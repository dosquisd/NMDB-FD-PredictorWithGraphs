{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f985dff",
   "metadata": {},
   "source": [
    "Well, in [002_calc_some_stats.ipynb](https://github.com/dosquisd/NMDB-FD-PredictorWithGraphs/blob/5952726527e9855ce448bb8a9d8ad7a7f33317ba/notebooks/002_calc_some_stats.ipynb) there was a lot of code, mixing creating dataset and plotting them, so I created this notebook to have a dedicated notebook, only to create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a0e79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b6cbf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import logging\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "\n",
    "import networkx as nx\n",
    "import nolds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from utils import (\n",
    "    MIN_VALUE_THRESHOLD,\n",
    "    ROOTDIR,\n",
    "    AdjacencyMethod,\n",
    "    DistanceTransformation,\n",
    "    EventData,\n",
    "    GraphEvent,\n",
    "    Normalizer,\n",
    "    encode_variables_to_filename,\n",
    "    get_events,\n",
    "    graph_fractal_dimension,\n",
    "    logger,\n",
    "    read_dataset,\n",
    ")\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "LOW__CUTOFF_RIGIDITY = 3.0\n",
    "HIGH__CUTOFF_RIGIDITY = 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a684b29f",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b1e4b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_graph_metrics(\n",
    "    events: Dict[str, EventData],\n",
    "    *,\n",
    "    threshold: float = 0.0,\n",
    "    valid_methods: Optional[List[AdjacencyMethod]] = None,\n",
    ") -> Tuple[pd.DataFrame, List[Dict[str, Any]]]:\n",
    "    def calculate_avg_node_metric(\n",
    "        metrics: Dict[str, float],\n",
    "        fn: Optional[Callable[[np.ndarray], float]] = None,\n",
    "        *,\n",
    "        value_per_node: Optional[Dict[str, float]] = None,\n",
    "    ) -> float:\n",
    "        if fn is None:\n",
    "            fn = lambda nums: float(nums.mean())  # noqa: E731\n",
    "\n",
    "        if value_per_node is None:\n",
    "            value_per_node = {}\n",
    "\n",
    "        values = np.array(\n",
    "            list(\n",
    "                map(\n",
    "                    lambda item: item[1] * value_per_node.get(item[0], 1.0),\n",
    "                    metrics.items(),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        return fn(values)\n",
    "\n",
    "    if valid_methods is None:\n",
    "        valid_methods = [AdjacencyMethod.MANHATTAN, AdjacencyMethod.MINKOWSKI]\n",
    "\n",
    "    # The same amount of iterations, but at least there's only one loop instead of 4 nested loops\n",
    "    dataset = []\n",
    "    combinations = itertools.product(\n",
    "        events.keys(), DistanceTransformation, Normalizer, valid_methods\n",
    "    )\n",
    "    for event_date, transform_method, normalization, adj_method in combinations:\n",
    "        data = events[event_date]\n",
    "        raw_df = data[\"raw\"].reset_index(drop=True)\n",
    "        logger.info(\n",
    "            f\"Processing event: {event_date} with transformation: {transform_method.value}, \"\n",
    "            f\"normalization: {normalization.value}, adjacency method: {adj_method.value}, \"\n",
    "            f\"raw shape: {raw_df.shape}\"\n",
    "        )\n",
    "\n",
    "        if transform_method == DistanceTransformation.LOG:\n",
    "            raw_df[raw_df.abs() < MIN_VALUE_THRESHOLD] = MIN_VALUE_THRESHOLD\n",
    "\n",
    "        # Transform raw_df data before any normalization\n",
    "        transformed_data = transform_method.transform(raw_df.to_numpy())\n",
    "        transformed_df = pd.DataFrame(transformed_data, columns=raw_df.columns)\n",
    "        transformed_df[transformed_df.abs() < MIN_VALUE_THRESHOLD] = MIN_VALUE_THRESHOLD\n",
    "\n",
    "        # Normalize data\n",
    "        columns = transformed_df.columns\n",
    "        normalized_data = normalization.normalize(transformed_df.to_numpy())\n",
    "        normalized_df = pd.DataFrame(normalized_data, columns=columns)\n",
    "        nan_sum = normalized_df.isna().sum()\n",
    "        nan_columns = nan_sum[nan_sum > 0].index.tolist()\n",
    "        if nan_columns:\n",
    "            logger.warning(f\"NAN COLUMNS DROPPED: {nan_columns}\")\n",
    "            normalized_df.drop(columns=nan_columns, inplace=True)\n",
    "\n",
    "        # normalized_df[normalized_df.abs() < MIN_VALUE_THRESHOLD] = MIN_VALUE_THRESHOLD\n",
    "\n",
    "        # Create graph event with the normalized data and metadata\n",
    "        graph_event = GraphEvent(\n",
    "            data=normalized_df,\n",
    "            metadata={\n",
    "                # Event metadata\n",
    "                \"drop\": data.get(\"drop\", 0.0),\n",
    "                \"intensity\": data.get(\"intensity\", \"Unknown\"),\n",
    "                \"dst\": data.get(\"dst\", 0.0),\n",
    "                # Station metadata\n",
    "                \"cutoff_rigidity\": data[\"cutoff_rigidity\"],\n",
    "                \"altitude\": data[\"altitude\"],\n",
    "            },\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            graph = graph_event.get_graph_networkx(adj_method, threshold=threshold)\n",
    "        except Exception as e:\n",
    "            logger.error(\n",
    "                f\"Error processing event {event_date} with method {adj_method.value}: {e}\"\n",
    "            )\n",
    "\n",
    "            print(\"\\nraw_df snapshot:\")\n",
    "            nan_sum = raw_df.isna().sum()\n",
    "            display(nan_sum[nan_sum > 0])\n",
    "\n",
    "            print(\"transformed_df snapshot:\")\n",
    "            nan_sum = transformed_df.isna().sum()\n",
    "            display(transformed_df)\n",
    "            display(nan_sum[nan_sum > 0])\n",
    "\n",
    "            print(\"normalized_df snapshot:\")\n",
    "            nan_sum = normalized_df.isna().sum()\n",
    "            display(normalized_df)\n",
    "            display(nan_sum[nan_sum > 0])\n",
    "\n",
    "            raise e\n",
    "\n",
    "        # Calculate MST and store it\n",
    "        graph = nx.minimum_spanning_tree(graph)\n",
    "        events[event_date][\"graphs\"][adj_method] = graph\n",
    "\n",
    "        # Weight distribution in order to calculate other metrics\n",
    "        weights = np.array(\n",
    "            list(map(lambda item: item[2][\"weight\"], graph.edges(data=True)))\n",
    "        )\n",
    "\n",
    "        # Node values for node-based (local) metrics\n",
    "        katz_centrality = nx.katz_centrality(graph)\n",
    "        closeness_centrality = nx.closeness_centrality(graph)\n",
    "        betweenness_centrality = nx.betweenness_centrality(graph)\n",
    "        laplacian_centrality = nx.laplacian_centrality(graph)\n",
    "\n",
    "        # Average node metrics per group (low, medium, high cutoff rigidity)\n",
    "        avg_per_group = {}\n",
    "        for (metric_name, centrality), interval in itertools.product(\n",
    "            (\n",
    "                (\"avg_katz\", katz_centrality),\n",
    "                (\"avg_closeness\", closeness_centrality),\n",
    "                (\"avg_betweenness\", betweenness_centrality),\n",
    "                (\"avg_laplacian\", laplacian_centrality),\n",
    "            ),\n",
    "            (\"low\", \"medium\", \"high\"),\n",
    "        ):\n",
    "            if interval == \"low\":\n",
    "                value_per_node = {\n",
    "                    node: 1.0 if rigidity < LOW__CUTOFF_RIGIDITY else 0.0\n",
    "                    for node, rigidity in graph_event.metadata[\n",
    "                        \"cutoff_rigidity\"\n",
    "                    ].items()\n",
    "                }\n",
    "            elif interval == \"medium\":\n",
    "                value_per_node = {\n",
    "                    node: 1.0\n",
    "                    if LOW__CUTOFF_RIGIDITY <= rigidity < HIGH__CUTOFF_RIGIDITY\n",
    "                    else 0.0\n",
    "                    for node, rigidity in graph_event.metadata[\n",
    "                        \"cutoff_rigidity\"\n",
    "                    ].items()\n",
    "                }\n",
    "            else:  # high\n",
    "                value_per_node = {\n",
    "                    node: 1.0 if rigidity >= HIGH__CUTOFF_RIGIDITY else 0.0\n",
    "                    for node, rigidity in graph_event.metadata[\n",
    "                        \"cutoff_rigidity\"\n",
    "                    ].items()\n",
    "                }\n",
    "\n",
    "            avg_per_group[metric_name + \"_\" + interval] = calculate_avg_node_metric(\n",
    "                centrality, value_per_node=value_per_node\n",
    "            )\n",
    "\n",
    "        # Global graph metrics\n",
    "        dataset.append(\n",
    "            {\n",
    "                \"event_date\": event_date,\n",
    "                # Event metadata\n",
    "                \"drop\": data.get(\"drop\", 0.0),\n",
    "                \"intensity\": data.get(\"intensity\", \"Unknown\"),\n",
    "                \"dst\": data.get(\"dst\", 0.0),\n",
    "                # Metric metadata\n",
    "                \"transformation\": transform_method.value,\n",
    "                \"normalization\": normalization.value,\n",
    "                \"adjacency_method\": adj_method.value,\n",
    "                \"graph\": graph,\n",
    "                # Graph global metrics\n",
    "                \"global_efficiency\": nx.global_efficiency(graph),\n",
    "                \"estrada_index\": nx.estrada_index(graph),\n",
    "                \"entropy\": entropy(weights),\n",
    "                \"fractal\": graph_fractal_dimension(graph, seed=37)[0],\n",
    "                \"hurst_rs\": nolds.hurst_rs(weights, fit=\"poly\"),\n",
    "                \"modularity\": nx.algorithms.community.modularity(\n",
    "                    graph,\n",
    "                    list(nx.algorithms.community.greedy_modularity_communities(graph)),\n",
    "                ),\n",
    "                \"assortativity\": nx.degree_assortativity_coefficient(graph),\n",
    "                # Average node metrics\n",
    "                \"avg_katz\": calculate_avg_node_metric(katz_centrality),\n",
    "                \"avg_closeness\": calculate_avg_node_metric(closeness_centrality),\n",
    "                \"avg_betweenness\": calculate_avg_node_metric(betweenness_centrality),\n",
    "                \"avg_laplacian\": calculate_avg_node_metric(laplacian_centrality),\n",
    "                # Average node metrics per group\n",
    "                **avg_per_group,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    dataset_df = pd.DataFrame(dataset)\n",
    "    return dataset_df, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d545393",
   "metadata": {},
   "source": [
    "### Save datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd975ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_adj_methods = [\n",
    "    AdjacencyMethod.MANHATTAN,\n",
    "    AdjacencyMethod.MINKOWSKI,\n",
    "]\n",
    "\n",
    "# Options for processing different files and configurations\n",
    "filename_options = [\"all.txt\", \"all.original.txt\", \"all.imp.txt\"]\n",
    "imput_data_options = [False, True]\n",
    "use_threshold_options = [False, True]\n",
    "\n",
    "options = itertools.product(filename_options, imput_data_options, use_threshold_options)\n",
    "for filename, imput_data, use_threshold in options:\n",
    "    if use_threshold != imput_data:\n",
    "        logger.info(\n",
    "            f\"Skipping file: {filename} with imput_data={imput_data} and \"\n",
    "            f\"use_threshold={use_threshold} (invalid combination)\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    logger.info(f\"Processing file: {filename} with imput_data={imput_data}\")\n",
    "    events = get_events(\n",
    "        filename=filename, imput_data=imput_data, use_threshold=use_threshold\n",
    "    )\n",
    "    dataset_df, dataset = calc_graph_metrics(events, valid_methods=valid_adj_methods)\n",
    "\n",
    "    logger.info(f\"Saving dataset for file: {filename} with imput_data={imput_data}\")\n",
    "    dataset_df.drop(columns=[\"graph\"]).to_csv(\n",
    "        ROOTDIR\n",
    "        / \"data\"\n",
    "        / encode_variables_to_filename(\n",
    "            event_filename=filename, imput_data=imput_data, use_threshold=use_threshold\n",
    "        ),\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba43d3e",
   "metadata": {},
   "source": [
    "## Read datasets to ensure are created properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2632420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>drop</th>\n",
       "      <th>intensity</th>\n",
       "      <th>dst</th>\n",
       "      <th>transformation</th>\n",
       "      <th>normalization</th>\n",
       "      <th>adjacency_method</th>\n",
       "      <th>global_efficiency</th>\n",
       "      <th>estrada_index</th>\n",
       "      <th>entropy</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_closeness_low</th>\n",
       "      <th>avg_closeness_medium</th>\n",
       "      <th>avg_closeness_high</th>\n",
       "      <th>avg_betweenness_low</th>\n",
       "      <th>avg_betweenness_medium</th>\n",
       "      <th>avg_betweenness_high</th>\n",
       "      <th>avg_laplacian_low</th>\n",
       "      <th>avg_laplacian_medium</th>\n",
       "      <th>avg_laplacian_high</th>\n",
       "      <th>graph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>6.57</td>\n",
       "      <td>G2</td>\n",
       "      <td>-213.0</td>\n",
       "      <td>none</td>\n",
       "      <td>min_max</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.260470</td>\n",
       "      <td>78.118375</td>\n",
       "      <td>3.425651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122219</td>\n",
       "      <td>0.043008</td>\n",
       "      <td>0.017454</td>\n",
       "      <td>0.132820</td>\n",
       "      <td>0.018023</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.048578</td>\n",
       "      <td>0.018893</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>(ATHN, MXCO, NANM, ROME, AATB, BKSN, JUNG, JUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>6.57</td>\n",
       "      <td>G2</td>\n",
       "      <td>-213.0</td>\n",
       "      <td>none</td>\n",
       "      <td>min_max</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0.262560</td>\n",
       "      <td>79.558149</td>\n",
       "      <td>3.432043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117957</td>\n",
       "      <td>0.040433</td>\n",
       "      <td>0.016817</td>\n",
       "      <td>0.139235</td>\n",
       "      <td>0.017717</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>0.019755</td>\n",
       "      <td>0.005055</td>\n",
       "      <td>(ATHN, MXCO, NANM, ROME, AATB, BKSN, JUNG, JUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>6.57</td>\n",
       "      <td>G2</td>\n",
       "      <td>-213.0</td>\n",
       "      <td>none</td>\n",
       "      <td>z_score</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.269012</td>\n",
       "      <td>80.006590</td>\n",
       "      <td>3.433672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>0.046529</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.113453</td>\n",
       "      <td>0.023766</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.041691</td>\n",
       "      <td>0.024559</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>(ATHN, MXCO, NANM, ROME, AATB, BKSN, JUNG, JUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>6.57</td>\n",
       "      <td>G2</td>\n",
       "      <td>-213.0</td>\n",
       "      <td>none</td>\n",
       "      <td>z_score</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0.275242</td>\n",
       "      <td>81.061524</td>\n",
       "      <td>3.406625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119887</td>\n",
       "      <td>0.053726</td>\n",
       "      <td>0.021017</td>\n",
       "      <td>0.101417</td>\n",
       "      <td>0.026149</td>\n",
       "      <td>0.012586</td>\n",
       "      <td>0.040507</td>\n",
       "      <td>0.022641</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>(ATHN, MXCO, NANM, ROME, AATB, BKSN, JUNG, JUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>6.57</td>\n",
       "      <td>G2</td>\n",
       "      <td>-213.0</td>\n",
       "      <td>none</td>\n",
       "      <td>robust</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.300785</td>\n",
       "      <td>84.485612</td>\n",
       "      <td>3.420624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141403</td>\n",
       "      <td>0.059335</td>\n",
       "      <td>0.027612</td>\n",
       "      <td>0.077224</td>\n",
       "      <td>0.031097</td>\n",
       "      <td>0.005437</td>\n",
       "      <td>0.045756</td>\n",
       "      <td>0.022627</td>\n",
       "      <td>0.007684</td>\n",
       "      <td>(ATHN, MXCO, NANM, ROME, AATB, BKSN, JUNG, JUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>2005-09-11</td>\n",
       "      <td>12.25</td>\n",
       "      <td>G3</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>robust</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0.370329</td>\n",
       "      <td>33.360243</td>\n",
       "      <td>2.587530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177041</td>\n",
       "      <td>0.029660</td>\n",
       "      <td>0.061841</td>\n",
       "      <td>0.142125</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.071795</td>\n",
       "      <td>0.090309</td>\n",
       "      <td>0.020465</td>\n",
       "      <td>0.044618</td>\n",
       "      <td>(ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>2005-09-11</td>\n",
       "      <td>12.25</td>\n",
       "      <td>G3</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>decimal_scaling</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.376799</td>\n",
       "      <td>33.796712</td>\n",
       "      <td>2.626843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190431</td>\n",
       "      <td>0.027422</td>\n",
       "      <td>0.053406</td>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.112813</td>\n",
       "      <td>0.010838</td>\n",
       "      <td>0.034985</td>\n",
       "      <td>(ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2005-09-11</td>\n",
       "      <td>12.25</td>\n",
       "      <td>G3</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>decimal_scaling</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0.385665</td>\n",
       "      <td>34.457961</td>\n",
       "      <td>2.618426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193768</td>\n",
       "      <td>0.031328</td>\n",
       "      <td>0.054469</td>\n",
       "      <td>0.160440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.112444</td>\n",
       "      <td>0.014234</td>\n",
       "      <td>0.033603</td>\n",
       "      <td>(ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>2005-09-11</td>\n",
       "      <td>12.25</td>\n",
       "      <td>G3</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>none</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.376799</td>\n",
       "      <td>33.796712</td>\n",
       "      <td>2.626843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190431</td>\n",
       "      <td>0.027422</td>\n",
       "      <td>0.053406</td>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.112813</td>\n",
       "      <td>0.010838</td>\n",
       "      <td>0.034985</td>\n",
       "      <td>(ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>2005-09-11</td>\n",
       "      <td>12.25</td>\n",
       "      <td>G3</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>none</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0.385665</td>\n",
       "      <td>34.457961</td>\n",
       "      <td>2.618426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193768</td>\n",
       "      <td>0.031328</td>\n",
       "      <td>0.054469</td>\n",
       "      <td>0.160440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.112444</td>\n",
       "      <td>0.014234</td>\n",
       "      <td>0.033603</td>\n",
       "      <td>(ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1020 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      event_date   drop intensity    dst transformation    normalization  \\\n",
       "0     2023-04-23   6.57        G2 -213.0           none          min_max   \n",
       "1     2023-04-23   6.57        G2 -213.0           none          min_max   \n",
       "2     2023-04-23   6.57        G2 -213.0           none          z_score   \n",
       "3     2023-04-23   6.57        G2 -213.0           none          z_score   \n",
       "4     2023-04-23   6.57        G2 -213.0           none           robust   \n",
       "...          ...    ...       ...    ...            ...              ...   \n",
       "1015  2005-09-11  12.25        G3 -139.0    exponential           robust   \n",
       "1016  2005-09-11  12.25        G3 -139.0    exponential  decimal_scaling   \n",
       "1017  2005-09-11  12.25        G3 -139.0    exponential  decimal_scaling   \n",
       "1018  2005-09-11  12.25        G3 -139.0    exponential             none   \n",
       "1019  2005-09-11  12.25        G3 -139.0    exponential             none   \n",
       "\n",
       "     adjacency_method  global_efficiency  estrada_index   entropy  ...  \\\n",
       "0           manhattan           0.260470      78.118375  3.425651  ...   \n",
       "1           minkowski           0.262560      79.558149  3.432043  ...   \n",
       "2           manhattan           0.269012      80.006590  3.433672  ...   \n",
       "3           minkowski           0.275242      81.061524  3.406625  ...   \n",
       "4           manhattan           0.300785      84.485612  3.420624  ...   \n",
       "...               ...                ...            ...       ...  ...   \n",
       "1015        minkowski           0.370329      33.360243  2.587530  ...   \n",
       "1016        manhattan           0.376799      33.796712  2.626843  ...   \n",
       "1017        minkowski           0.385665      34.457961  2.618426  ...   \n",
       "1018        manhattan           0.376799      33.796712  2.626843  ...   \n",
       "1019        minkowski           0.385665      34.457961  2.618426  ...   \n",
       "\n",
       "      avg_closeness_low  avg_closeness_medium  avg_closeness_high  \\\n",
       "0              0.122219              0.043008            0.017454   \n",
       "1              0.117957              0.040433            0.016817   \n",
       "2              0.120643              0.046529            0.020508   \n",
       "3              0.119887              0.053726            0.021017   \n",
       "4              0.141403              0.059335            0.027612   \n",
       "...                 ...                   ...                 ...   \n",
       "1015           0.177041              0.029660            0.061841   \n",
       "1016           0.190431              0.027422            0.053406   \n",
       "1017           0.193768              0.031328            0.054469   \n",
       "1018           0.190431              0.027422            0.053406   \n",
       "1019           0.193768              0.031328            0.054469   \n",
       "\n",
       "      avg_betweenness_low  avg_betweenness_medium  avg_betweenness_high  \\\n",
       "0                0.132820                0.018023              0.001894   \n",
       "1                0.139235                0.017717              0.001894   \n",
       "2                0.113453                0.023766              0.009531   \n",
       "3                0.101417                0.026149              0.012586   \n",
       "4                0.077224                0.031097              0.005437   \n",
       "...                   ...                     ...                   ...   \n",
       "1015             0.142125                0.009524              0.071795   \n",
       "1016             0.169231                0.000000              0.051282   \n",
       "1017             0.160440                0.000000              0.051282   \n",
       "1018             0.169231                0.000000              0.051282   \n",
       "1019             0.160440                0.000000              0.051282   \n",
       "\n",
       "      avg_laplacian_low  avg_laplacian_medium  avg_laplacian_high  \\\n",
       "0              0.048578              0.018893            0.004967   \n",
       "1              0.048802              0.019755            0.005055   \n",
       "2              0.041691              0.024559            0.008078   \n",
       "3              0.040507              0.022641            0.010740   \n",
       "4              0.045756              0.022627            0.007684   \n",
       "...                 ...                   ...                 ...   \n",
       "1015           0.090309              0.020465            0.044618   \n",
       "1016           0.112813              0.010838            0.034985   \n",
       "1017           0.112444              0.014234            0.033603   \n",
       "1018           0.112813              0.010838            0.034985   \n",
       "1019           0.112444              0.014234            0.033603   \n",
       "\n",
       "                                                  graph  \n",
       "0     (ATHN, MXCO, NANM, ROME, AATB, BKSN, JUNG, JUN...  \n",
       "1     (ATHN, MXCO, NANM, ROME, AATB, BKSN, JUNG, JUN...  \n",
       "2     (ATHN, MXCO, NANM, ROME, AATB, BKSN, JUNG, JUN...  \n",
       "3     (ATHN, MXCO, NANM, ROME, AATB, BKSN, JUNG, JUN...  \n",
       "4     (ATHN, MXCO, NANM, ROME, AATB, BKSN, JUNG, JUN...  \n",
       "...                                                 ...  \n",
       "1015  (ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...  \n",
       "1016  (ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...  \n",
       "1017  (ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...  \n",
       "1018  (ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...  \n",
       "1019  (ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...  \n",
       "\n",
       "[1020 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dataset(ROOTDIR / \"data\" / \"dataset_all_imput-False_threshold-False.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmdb-fd-predictorwithgraphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
