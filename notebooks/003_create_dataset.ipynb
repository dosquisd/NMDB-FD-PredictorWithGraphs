{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f985dff",
   "metadata": {},
   "source": [
    "Well, in [002_calc_some_stats.ipynb](https://github.com/dosquisd/NMDB-FD-PredictorWithGraphs/blob/5952726527e9855ce448bb8a9d8ad7a7f33317ba/notebooks/002_calc_some_stats.ipynb) there was a lot of code, mixing creating dataset and plotting them, so I created this notebook to have a dedicated notebook, only to create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a0e79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b6cbf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import logging\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "\n",
    "import networkx as nx\n",
    "import nolds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from utils import (\n",
    "    MIN_VALUE_THRESHOLD,\n",
    "    ROOTDIR,\n",
    "    AdjacencyMethod,\n",
    "    DistanceTransformation,\n",
    "    EventData,\n",
    "    GraphEvent,\n",
    "    Normalizer,\n",
    "    encode_variables_to_filename,\n",
    "    get_events,\n",
    "    graph_fractal_dimension,\n",
    "    logger,\n",
    "    read_dataset,\n",
    ")\n",
    "\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a684b29f",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b1e4b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_graph_metrics(\n",
    "    events: Dict[str, EventData],\n",
    "    *,\n",
    "    threshold: float = 0.0,\n",
    "    valid_methods: Optional[List[AdjacencyMethod]] = None,\n",
    ") -> Tuple[pd.DataFrame, List[Dict[str, Any]]]:\n",
    "    def calculate_avg_node_metric(\n",
    "        metrics: Dict[str, float],\n",
    "        fn: Optional[Callable[[np.ndarray], float]] = None,\n",
    "        *,\n",
    "        value_per_node: Optional[Dict[str, float]] = None,\n",
    "    ) -> float:\n",
    "        if fn is None:\n",
    "            fn = lambda nums: float(nums.mean())  # noqa: E731\n",
    "\n",
    "        if value_per_node is None:\n",
    "            value_per_node = {}\n",
    "\n",
    "        values = np.array(\n",
    "            list(\n",
    "                map(\n",
    "                    lambda item: item[1] * value_per_node.get(item[0], 1.0),\n",
    "                    metrics.items(),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        return fn(values)\n",
    "\n",
    "    if valid_methods is None:\n",
    "        valid_methods = [AdjacencyMethod.MANHATTAN, AdjacencyMethod.MINKOWSKI]\n",
    "\n",
    "    # The same amount of iterations, but at least there's only one loop instead of 4 nested loops\n",
    "    dataset = []\n",
    "    combinations = itertools.product(\n",
    "        events.keys(), DistanceTransformation, Normalizer, valid_methods\n",
    "    )\n",
    "    for event_date, transform_method, normalization, adj_method in combinations:\n",
    "        data = events[event_date]\n",
    "        raw_df = data[\"raw\"].reset_index(drop=True)\n",
    "        logger.info(\n",
    "            f\"Processing event: {event_date} with transformation: {transform_method.value}, \"\n",
    "            f\"normalization: {normalization.value}, adjacency method: {adj_method.value}, \"\n",
    "            f\"raw shape: {raw_df.shape}\"\n",
    "        )\n",
    "\n",
    "        if transform_method == DistanceTransformation.LOG:\n",
    "            raw_df[raw_df.abs() < MIN_VALUE_THRESHOLD] = MIN_VALUE_THRESHOLD\n",
    "\n",
    "        # Transform raw_df data before any normalization\n",
    "        transformed_data = transform_method.transform(raw_df.to_numpy())\n",
    "        transformed_df = pd.DataFrame(transformed_data, columns=raw_df.columns)\n",
    "        transformed_df[transformed_df.abs() < MIN_VALUE_THRESHOLD] = MIN_VALUE_THRESHOLD\n",
    "\n",
    "        # Normalize data\n",
    "        columns = transformed_df.columns\n",
    "        normalized_data = normalization.normalize(transformed_df.to_numpy())\n",
    "        normalized_df = pd.DataFrame(normalized_data, columns=columns)\n",
    "        nan_sum = normalized_df.isna().sum()\n",
    "        nan_columns = nan_sum[nan_sum > 0].index.tolist()\n",
    "        if nan_columns:\n",
    "            logger.warning(f\"NAN COLUMNS DROPPED: {nan_columns}\")\n",
    "            normalized_df.drop(columns=nan_columns, inplace=True)\n",
    "\n",
    "        # normalized_df[normalized_df.abs() < MIN_VALUE_THRESHOLD] = MIN_VALUE_THRESHOLD\n",
    "\n",
    "        # Create graph event with the normalized data and metadata\n",
    "        graph_event = GraphEvent(\n",
    "            data=normalized_df,\n",
    "            metadata={\n",
    "                # Event metadata\n",
    "                \"drop\": data.get(\"drop\", 0.0),\n",
    "                \"intensity\": data.get(\"intensity\", \"Unknown\"),\n",
    "                \"dst\": data.get(\"dst\", 0.0),\n",
    "                # Station metadata\n",
    "                \"cutoff_rigidity\": data[\"cutoff_rigidity\"],\n",
    "                \"altitude\": data[\"altitude\"],\n",
    "            },\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            graph = graph_event.get_graph_networkx(adj_method, threshold=threshold)\n",
    "        except Exception as e:\n",
    "            logger.error(\n",
    "                f\"Error processing event {event_date} with method {adj_method.value}: {e}\"\n",
    "            )\n",
    "\n",
    "            print(\"\\nraw_df snapshot:\")\n",
    "            nan_sum = raw_df.isna().sum()\n",
    "            display(nan_sum[nan_sum > 0])\n",
    "\n",
    "            print(\"transformed_df snapshot:\")\n",
    "            nan_sum = transformed_df.isna().sum()\n",
    "            display(transformed_df)\n",
    "            display(nan_sum[nan_sum > 0])\n",
    "\n",
    "            print(\"normalized_df snapshot:\")\n",
    "            nan_sum = normalized_df.isna().sum()\n",
    "            display(normalized_df)\n",
    "            display(nan_sum[nan_sum > 0])\n",
    "\n",
    "            raise e\n",
    "\n",
    "        # Calculate MST and store it\n",
    "        graph = nx.minimum_spanning_tree(graph)\n",
    "        events[event_date][\"graphs\"][adj_method] = graph\n",
    "\n",
    "        # Weight distribution in order to calculate other metrics\n",
    "        weights = np.array(\n",
    "            list(map(lambda item: item[2][\"weight\"], graph.edges(data=True)))\n",
    "        )\n",
    "\n",
    "        # Global graph metrics\n",
    "        dataset.append(\n",
    "            {\n",
    "                \"event_date\": event_date,\n",
    "                # Event metadata\n",
    "                \"drop\": data.get(\"drop\", 0.0),\n",
    "                \"intensity\": data.get(\"intensity\", \"Unknown\"),\n",
    "                \"dst\": data.get(\"dst\", 0.0),\n",
    "                # Metric metadata\n",
    "                \"transformation\": transform_method.value,\n",
    "                \"normalization\": normalization.value,\n",
    "                \"adjacency_method\": adj_method.value,\n",
    "                \"graph\": graph,\n",
    "                # Graph global metrics\n",
    "                \"global_efficiency\": nx.global_efficiency(graph),\n",
    "                \"estrada_index\": nx.estrada_index(graph),\n",
    "                \"entropy\": entropy(weights),\n",
    "                \"fractal\": graph_fractal_dimension(graph, seed=37)[0],\n",
    "                \"hurst_rs\": nolds.hurst_rs(weights, fit=\"poly\"),\n",
    "                \"modularity\": nx.algorithms.community.modularity(\n",
    "                    graph,\n",
    "                    list(nx.algorithms.community.greedy_modularity_communities(graph)),\n",
    "                ),\n",
    "                \"assortativity\": nx.degree_assortativity_coefficient(graph),\n",
    "                # Average node metrics\n",
    "                \"avg_katz\": calculate_avg_node_metric(nx.katz_centrality(graph)),\n",
    "                \"avg_closeness\": calculate_avg_node_metric(\n",
    "                    nx.closeness_centrality(graph)\n",
    "                ),\n",
    "                \"avg_betweenness\": calculate_avg_node_metric(\n",
    "                    nx.betweenness_centrality(graph)\n",
    "                ),\n",
    "                \"avg_laplacian\": calculate_avg_node_metric(\n",
    "                    nx.laplacian_centrality(graph)\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    dataset_df = pd.DataFrame(dataset)\n",
    "    return dataset_df, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d545393",
   "metadata": {},
   "source": [
    "### Save datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd975ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_adj_methods = [\n",
    "    AdjacencyMethod.MANHATTAN,\n",
    "    AdjacencyMethod.MINKOWSKI,\n",
    "]\n",
    "\n",
    "# Options for processing different files and configurations\n",
    "filename_options = [\"all.txt\", \"all.original.txt\", \"all.imp.txt\"]\n",
    "imput_data_options = [False, True]\n",
    "use_threshold_options = [False, True]\n",
    "\n",
    "options = itertools.product(filename_options, imput_data_options, use_threshold_options)\n",
    "for filename, imput_data, use_threshold in options:\n",
    "    if use_threshold != imput_data:\n",
    "        logger.info(\n",
    "            f\"Skipping file: {filename} with imput_data={imput_data} and \"\n",
    "            f\"use_threshold={use_threshold} (invalid combination)\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    logger.info(f\"Processing file: {filename} with imput_data={imput_data}\")\n",
    "    events = get_events(\n",
    "        filename=filename, imput_data=imput_data, use_threshold=use_threshold\n",
    "    )\n",
    "    dataset_df, dataset = calc_graph_metrics(events, valid_methods=valid_adj_methods)\n",
    "\n",
    "    logger.info(f\"Saving dataset for file: {filename} with imput_data={imput_data}\")\n",
    "    dataset_df.drop(columns=[\"graph\"]).to_csv(\n",
    "        ROOTDIR\n",
    "        / \"data\"\n",
    "        / encode_variables_to_filename(\n",
    "            event_filename=filename, imput_data=imput_data, use_threshold=use_threshold\n",
    "        ),\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba43d3e",
   "metadata": {},
   "source": [
    "## Read datasets to ensure are created properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2632420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>drop</th>\n",
       "      <th>intensity</th>\n",
       "      <th>dst</th>\n",
       "      <th>transformation</th>\n",
       "      <th>normalization</th>\n",
       "      <th>adjacency_method</th>\n",
       "      <th>global_efficiency</th>\n",
       "      <th>estrada_index</th>\n",
       "      <th>entropy</th>\n",
       "      <th>fractal</th>\n",
       "      <th>hurst_rs</th>\n",
       "      <th>modularity</th>\n",
       "      <th>assortativity</th>\n",
       "      <th>avg_katz</th>\n",
       "      <th>avg_closeness</th>\n",
       "      <th>avg_betweenness</th>\n",
       "      <th>avg_laplacian</th>\n",
       "      <th>graph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>15.32</td>\n",
       "      <td>G5</td>\n",
       "      <td>-412.0</td>\n",
       "      <td>none</td>\n",
       "      <td>min_max</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.282992</td>\n",
       "      <td>73.135234</td>\n",
       "      <td>3.343178</td>\n",
       "      <td>1.278966</td>\n",
       "      <td>0.570866</td>\n",
       "      <td>0.668313</td>\n",
       "      <td>-0.314667</td>\n",
       "      <td>0.180939</td>\n",
       "      <td>0.186933</td>\n",
       "      <td>0.165764</td>\n",
       "      <td>0.081755</td>\n",
       "      <td>(MXCO, NANM, CALM, ROME, AATB, BKSN, JUNG, JUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>15.32</td>\n",
       "      <td>G5</td>\n",
       "      <td>-412.0</td>\n",
       "      <td>none</td>\n",
       "      <td>min_max</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0.284762</td>\n",
       "      <td>72.870807</td>\n",
       "      <td>3.343198</td>\n",
       "      <td>1.322432</td>\n",
       "      <td>0.529297</td>\n",
       "      <td>0.669813</td>\n",
       "      <td>-0.295971</td>\n",
       "      <td>0.180983</td>\n",
       "      <td>0.192791</td>\n",
       "      <td>0.158128</td>\n",
       "      <td>0.081376</td>\n",
       "      <td>(MXCO, NANM, CALM, ROME, AATB, BKSN, JUNG, JUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>15.32</td>\n",
       "      <td>G5</td>\n",
       "      <td>-412.0</td>\n",
       "      <td>none</td>\n",
       "      <td>z_score</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.291746</td>\n",
       "      <td>73.483465</td>\n",
       "      <td>3.336238</td>\n",
       "      <td>1.216267</td>\n",
       "      <td>0.204672</td>\n",
       "      <td>0.676643</td>\n",
       "      <td>-0.393393</td>\n",
       "      <td>0.180861</td>\n",
       "      <td>0.203899</td>\n",
       "      <td>0.145402</td>\n",
       "      <td>0.081349</td>\n",
       "      <td>(MXCO, NANM, CALM, ROME, AATB, BKSN, JUNG, JUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>15.32</td>\n",
       "      <td>G5</td>\n",
       "      <td>-412.0</td>\n",
       "      <td>none</td>\n",
       "      <td>z_score</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0.270104</td>\n",
       "      <td>71.694679</td>\n",
       "      <td>3.335221</td>\n",
       "      <td>1.263404</td>\n",
       "      <td>0.457441</td>\n",
       "      <td>0.671031</td>\n",
       "      <td>-0.418754</td>\n",
       "      <td>0.181306</td>\n",
       "      <td>0.172011</td>\n",
       "      <td>0.178407</td>\n",
       "      <td>0.080409</td>\n",
       "      <td>(MXCO, NANM, CALM, ROME, AATB, BKSN, JUNG, JUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>15.32</td>\n",
       "      <td>G5</td>\n",
       "      <td>-412.0</td>\n",
       "      <td>none</td>\n",
       "      <td>robust</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.293525</td>\n",
       "      <td>72.553556</td>\n",
       "      <td>3.320189</td>\n",
       "      <td>1.382974</td>\n",
       "      <td>0.301323</td>\n",
       "      <td>0.672425</td>\n",
       "      <td>-0.293582</td>\n",
       "      <td>0.181019</td>\n",
       "      <td>0.210933</td>\n",
       "      <td>0.139655</td>\n",
       "      <td>0.080683</td>\n",
       "      <td>(MXCO, NANM, CALM, ROME, AATB, BKSN, JUNG, JUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>2005-09-11</td>\n",
       "      <td>12.25</td>\n",
       "      <td>G3</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>robust</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0.370329</td>\n",
       "      <td>33.360243</td>\n",
       "      <td>2.587530</td>\n",
       "      <td>1.406931</td>\n",
       "      <td>0.470459</td>\n",
       "      <td>0.518883</td>\n",
       "      <td>-0.340426</td>\n",
       "      <td>0.257540</td>\n",
       "      <td>0.268541</td>\n",
       "      <td>0.223443</td>\n",
       "      <td>0.155391</td>\n",
       "      <td>(ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>2005-09-11</td>\n",
       "      <td>12.25</td>\n",
       "      <td>G3</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>decimal_scaling</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.376799</td>\n",
       "      <td>33.796712</td>\n",
       "      <td>2.626843</td>\n",
       "      <td>1.280921</td>\n",
       "      <td>0.600347</td>\n",
       "      <td>0.529771</td>\n",
       "      <td>-0.477778</td>\n",
       "      <td>0.257264</td>\n",
       "      <td>0.271259</td>\n",
       "      <td>0.220513</td>\n",
       "      <td>0.158636</td>\n",
       "      <td>(ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2005-09-11</td>\n",
       "      <td>12.25</td>\n",
       "      <td>G3</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>decimal_scaling</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0.385665</td>\n",
       "      <td>34.457961</td>\n",
       "      <td>2.618426</td>\n",
       "      <td>1.256231</td>\n",
       "      <td>0.519619</td>\n",
       "      <td>0.528008</td>\n",
       "      <td>-0.607843</td>\n",
       "      <td>0.256903</td>\n",
       "      <td>0.279565</td>\n",
       "      <td>0.211722</td>\n",
       "      <td>0.160281</td>\n",
       "      <td>(ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>2005-09-11</td>\n",
       "      <td>12.25</td>\n",
       "      <td>G3</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>none</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.376799</td>\n",
       "      <td>33.796712</td>\n",
       "      <td>2.626843</td>\n",
       "      <td>1.280921</td>\n",
       "      <td>0.600347</td>\n",
       "      <td>0.529771</td>\n",
       "      <td>-0.477778</td>\n",
       "      <td>0.257264</td>\n",
       "      <td>0.271259</td>\n",
       "      <td>0.220513</td>\n",
       "      <td>0.158636</td>\n",
       "      <td>(ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>2005-09-11</td>\n",
       "      <td>12.25</td>\n",
       "      <td>G3</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>none</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0.385665</td>\n",
       "      <td>34.457961</td>\n",
       "      <td>2.618426</td>\n",
       "      <td>1.256231</td>\n",
       "      <td>0.519619</td>\n",
       "      <td>0.528008</td>\n",
       "      <td>-0.607843</td>\n",
       "      <td>0.256903</td>\n",
       "      <td>0.279565</td>\n",
       "      <td>0.211722</td>\n",
       "      <td>0.160281</td>\n",
       "      <td>(ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1020 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      event_date   drop intensity    dst transformation    normalization  \\\n",
       "0     2024-05-10  15.32        G5 -412.0           none          min_max   \n",
       "1     2024-05-10  15.32        G5 -412.0           none          min_max   \n",
       "2     2024-05-10  15.32        G5 -412.0           none          z_score   \n",
       "3     2024-05-10  15.32        G5 -412.0           none          z_score   \n",
       "4     2024-05-10  15.32        G5 -412.0           none           robust   \n",
       "...          ...    ...       ...    ...            ...              ...   \n",
       "1015  2005-09-11  12.25        G3 -139.0    exponential           robust   \n",
       "1016  2005-09-11  12.25        G3 -139.0    exponential  decimal_scaling   \n",
       "1017  2005-09-11  12.25        G3 -139.0    exponential  decimal_scaling   \n",
       "1018  2005-09-11  12.25        G3 -139.0    exponential             none   \n",
       "1019  2005-09-11  12.25        G3 -139.0    exponential             none   \n",
       "\n",
       "     adjacency_method  global_efficiency  estrada_index   entropy   fractal  \\\n",
       "0           manhattan           0.282992      73.135234  3.343178  1.278966   \n",
       "1           minkowski           0.284762      72.870807  3.343198  1.322432   \n",
       "2           manhattan           0.291746      73.483465  3.336238  1.216267   \n",
       "3           minkowski           0.270104      71.694679  3.335221  1.263404   \n",
       "4           manhattan           0.293525      72.553556  3.320189  1.382974   \n",
       "...               ...                ...            ...       ...       ...   \n",
       "1015        minkowski           0.370329      33.360243  2.587530  1.406931   \n",
       "1016        manhattan           0.376799      33.796712  2.626843  1.280921   \n",
       "1017        minkowski           0.385665      34.457961  2.618426  1.256231   \n",
       "1018        manhattan           0.376799      33.796712  2.626843  1.280921   \n",
       "1019        minkowski           0.385665      34.457961  2.618426  1.256231   \n",
       "\n",
       "      hurst_rs  modularity  assortativity  avg_katz  avg_closeness  \\\n",
       "0     0.570866    0.668313      -0.314667  0.180939       0.186933   \n",
       "1     0.529297    0.669813      -0.295971  0.180983       0.192791   \n",
       "2     0.204672    0.676643      -0.393393  0.180861       0.203899   \n",
       "3     0.457441    0.671031      -0.418754  0.181306       0.172011   \n",
       "4     0.301323    0.672425      -0.293582  0.181019       0.210933   \n",
       "...        ...         ...            ...       ...            ...   \n",
       "1015  0.470459    0.518883      -0.340426  0.257540       0.268541   \n",
       "1016  0.600347    0.529771      -0.477778  0.257264       0.271259   \n",
       "1017  0.519619    0.528008      -0.607843  0.256903       0.279565   \n",
       "1018  0.600347    0.529771      -0.477778  0.257264       0.271259   \n",
       "1019  0.519619    0.528008      -0.607843  0.256903       0.279565   \n",
       "\n",
       "      avg_betweenness  avg_laplacian  \\\n",
       "0            0.165764       0.081755   \n",
       "1            0.158128       0.081376   \n",
       "2            0.145402       0.081349   \n",
       "3            0.178407       0.080409   \n",
       "4            0.139655       0.080683   \n",
       "...               ...            ...   \n",
       "1015         0.223443       0.155391   \n",
       "1016         0.220513       0.158636   \n",
       "1017         0.211722       0.160281   \n",
       "1018         0.220513       0.158636   \n",
       "1019         0.211722       0.160281   \n",
       "\n",
       "                                                  graph  \n",
       "0     (MXCO, NANM, CALM, ROME, AATB, BKSN, JUNG, JUN...  \n",
       "1     (MXCO, NANM, CALM, ROME, AATB, BKSN, JUNG, JUN...  \n",
       "2     (MXCO, NANM, CALM, ROME, AATB, BKSN, JUNG, JUN...  \n",
       "3     (MXCO, NANM, CALM, ROME, AATB, BKSN, JUNG, JUN...  \n",
       "4     (MXCO, NANM, CALM, ROME, AATB, BKSN, JUNG, JUN...  \n",
       "...                                                 ...  \n",
       "1015  (ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...  \n",
       "1016  (ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...  \n",
       "1017  (ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...  \n",
       "1018  (ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...  \n",
       "1019  (ESOI, MXCO, ROME, AATB, LMKS, MOSC, NEWK, CAL...  \n",
       "\n",
       "[1020 rows x 19 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dataset(ROOTDIR / \"data\" / \"dataset_all_imput-False_threshold-False.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
