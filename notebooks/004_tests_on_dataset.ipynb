{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aae59e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7e8a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from utils import (\n",
    "    ROOTDIR,\n",
    "    AdjacencyMethod,\n",
    "    DistanceTransformation,\n",
    "    Normalizer,\n",
    "    encode_variables_to_filename,\n",
    "    read_dataset,\n",
    "    setup_plotting,\n",
    ")\n",
    "\n",
    "setup_plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d582feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_COLUMNS = [\n",
    "    \"global_efficiency\",  # x1\n",
    "    \"entropy\",  # x2\n",
    "    \"hurst_rs\",  # x3\n",
    "    \"fractal\",  # x4\n",
    "    \"modularity\",  # x5\n",
    "    \"assortativity\",  # x6\n",
    "    \"estrada_index\",  # x7\n",
    "    \"avg_katz\",  # x8\n",
    "    \"avg_closeness\",  # x9\n",
    "    \"avg_betweenness\",  # x10\n",
    "    \"avg_laplacian\",  # x11\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aee693",
   "metadata": {},
   "source": [
    "## Choose configuration\n",
    "\n",
    "Depending on the configuration desired, we get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adeb9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_filename(\n",
    "    event_filename: str = \"all.txt\",\n",
    "    input_data: bool = False,\n",
    "    use_threshold: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    filename = encode_variables_to_filename(\n",
    "        event_filename=event_filename,\n",
    "        imput_data=input_data,\n",
    "        use_threshold=use_threshold,\n",
    "    )\n",
    "\n",
    "    dataset_df = read_dataset(ROOTDIR / \"data\" / filename)\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8096e431",
   "metadata": {},
   "source": [
    "### Configuration 1\n",
    "\n",
    "* Default data per event: `event_filename = \"all.txt\"`\n",
    "* Without inputing data: `input_data = False`\n",
    "* If the column have nan, drop it: `use_threshold = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63fed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_filename = \"all.txt\"\n",
    "input_data = False\n",
    "use_threshold = False\n",
    "\n",
    "dataset_df_conf1 = get_dataset_filename(\n",
    "    event_filename=\"all.txt\",\n",
    "    input_data=False,\n",
    "    use_threshold=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de271dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.404\n",
      "Model:                            OLS   Adj. R-squared:                  0.131\n",
      "Method:                 Least Squares   F-statistic:                     1.480\n",
      "Date:                Mon, 09 Feb 2026   Prob (F-statistic):              0.203\n",
      "Time:                        00:58:17   Log-Likelihood:                -48.283\n",
      "No. Observations:                  36   AIC:                             120.6\n",
      "Df Residuals:                      24   BIC:                             139.6\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         51.4512    108.306      0.475      0.639    -172.081     274.984\n",
      "x1            -7.9570     94.022     -0.085      0.933    -202.009     186.095\n",
      "x2            -1.1111     16.400     -0.068      0.947     -34.959      32.737\n",
      "x3            -0.4544      1.857     -0.245      0.809      -4.288       3.379\n",
      "x4            -0.1857      2.430     -0.076      0.940      -5.201       4.829\n",
      "x5            17.7972     11.746      1.515      0.143      -6.445      42.040\n",
      "x6             4.7715      2.201      2.168      0.040       0.230       9.313\n",
      "x7            -0.1728      0.093     -1.852      0.076      -0.365       0.020\n",
      "x8          -415.1310    324.506     -1.279      0.213   -1084.878     254.616\n",
      "x9            35.5143     60.881      0.583      0.565     -90.139     161.167\n",
      "x10           52.9165     38.545      1.373      0.182     -26.636     132.469\n",
      "x11          268.6530    187.404      1.434      0.165    -118.129     655.435\n",
      "==============================================================================\n",
      "Omnibus:                        3.288   Durbin-Watson:                   1.128\n",
      "Prob(Omnibus):                  0.193   Jarque-Bera (JB):                2.374\n",
      "Skew:                           0.169   Prob(JB):                        0.305\n",
      "Kurtosis:                       4.212   Cond. No.                     1.07e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.07e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "distance_transformation = DistanceTransformation.EXPONENTIAL\n",
    "norm_method = Normalizer.Z_SCORE\n",
    "adjacency_method = AdjacencyMethod.MANHATTAN\n",
    "\n",
    "df0 = dataset_df_conf1[\n",
    "    (dataset_df_conf1[\"transformation\"] == distance_transformation.value)\n",
    "    & (dataset_df_conf1[\"normalization\"] == norm_method.value)\n",
    "    & (dataset_df_conf1[\"adjacency_method\"] == adjacency_method.value)\n",
    "].sort_values(by=\"intensity\")[[*METRIC_COLUMNS, \"intensity\"]]\n",
    "\n",
    "x0 = df0.drop(columns=[\"intensity\"]).astype(float).values\n",
    "y = (\n",
    "    df0[\"intensity\"]\n",
    "    .replace(\n",
    "        [\"G1\", \"G2\", \"G3\", \"G4\", \"G5\", \"Unknown\", np.nan, \"G4/G5\", \"G3/G4\"],\n",
    "        [1, 2, 3, 4, 5, 0, 0, 4.5, 3.5],\n",
    "    )\n",
    "    .astype(float)\n",
    "    .values\n",
    ")\n",
    "\n",
    "x0 = sm.add_constant(x0)  # Adds a constant term to the predictor\n",
    "model = sm.OLS(y, x0).fit()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fb0f7c",
   "metadata": {},
   "source": [
    "## Configuration 2\n",
    "\n",
    "* Imputed data previously: `event_filename = \"all.imp.txt\"`\n",
    "* Without imputing data on my own: `input_data = False`\n",
    "* If the column have nans, drop it: `use_threshold = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cdc2eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df_conf2 = get_dataset_filename(\n",
    "    event_filename=\"all.imp.txt\",\n",
    "    input_data=False,\n",
    "    use_threshold=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5fa1aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.397\n",
      "Model:                            OLS   Adj. R-squared:                  0.120\n",
      "Method:                 Least Squares   F-statistic:                     1.435\n",
      "Date:                Mon, 09 Feb 2026   Prob (F-statistic):              0.221\n",
      "Time:                        00:58:29   Log-Likelihood:                -48.506\n",
      "No. Observations:                  36   AIC:                             121.0\n",
      "Df Residuals:                      24   BIC:                             140.0\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        118.5142     73.474      1.613      0.120     -33.128     270.157\n",
      "x1           -32.5368     82.808     -0.393      0.698    -203.443     138.370\n",
      "x2            -7.6112      9.792     -0.777      0.445     -27.820      12.598\n",
      "x3            -0.5149      1.562     -0.330      0.745      -3.739       2.710\n",
      "x4             1.5057      2.024      0.744      0.464      -2.671       5.682\n",
      "x5            -4.5708     11.026     -0.415      0.682     -27.326      18.185\n",
      "x6             2.3276      1.722      1.352      0.189      -1.226       5.881\n",
      "x7            -0.2618      0.093     -2.818      0.010      -0.454      -0.070\n",
      "x8          -490.1904    271.620     -1.805      0.084   -1050.786      70.405\n",
      "x9            39.3659     56.843      0.693      0.495     -77.952     156.684\n",
      "x10           38.8576     43.768      0.888      0.383     -51.475     129.190\n",
      "x11          209.5830    191.054      1.097      0.284    -184.732     603.898\n",
      "==============================================================================\n",
      "Omnibus:                        0.266   Durbin-Watson:                   0.884\n",
      "Prob(Omnibus):                  0.876   Jarque-Bera (JB):                0.226\n",
      "Skew:                          -0.171   Prob(JB):                        0.893\n",
      "Kurtosis:                       2.815   Cond. No.                     1.05e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.05e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "distance_transformation = DistanceTransformation.EXPONENTIAL\n",
    "norm_method = Normalizer.Z_SCORE\n",
    "adjacency_method = AdjacencyMethod.MANHATTAN\n",
    "\n",
    "df0 = dataset_df_conf2[\n",
    "    (dataset_df_conf2[\"transformation\"] == distance_transformation.value)\n",
    "    & (dataset_df_conf2[\"normalization\"] == norm_method.value)\n",
    "    & (dataset_df_conf2[\"adjacency_method\"] == adjacency_method.value)\n",
    "].sort_values(by=\"intensity\")[[*METRIC_COLUMNS, \"intensity\"]]\n",
    "\n",
    "x0 = df0.drop(columns=[\"intensity\"]).astype(float).values\n",
    "y = (\n",
    "    df0[\"intensity\"]\n",
    "    .replace(\n",
    "        [\"G1\", \"G2\", \"G3\", \"G4\", \"G5\", \"Unknown\", np.nan, \"G4/G5\", \"G3/G4\"],\n",
    "        [1, 2, 3, 4, 5, 0, 0, 4.5, 3.5],\n",
    "    )\n",
    "    .astype(float)\n",
    "    .values\n",
    ")\n",
    "\n",
    "x0 = sm.add_constant(x0)  # Adds a constant term to the predictor\n",
    "model = sm.OLS(y, x0).fit()\n",
    "print(model.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
