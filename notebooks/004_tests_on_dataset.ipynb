{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6aae59e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7e8a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from typing import Any, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from utils import (\n",
    "    METRIC_COLUMNS,\n",
    "    ROOTDIR,\n",
    "    AdjacencyMethod,\n",
    "    DistanceTransformation,\n",
    "    Normalizer,\n",
    "    encode_variables_to_filename,\n",
    "    get_dataset_filename,\n",
    "    setup_plotting,\n",
    ")\n",
    "\n",
    "setup_plotting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aee693",
   "metadata": {},
   "source": [
    "## Choose configuration\n",
    "\n",
    "Depending on the configuration desired, we get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeb9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h0_condition(p_values: pd.Series, alpha: float = 0.09) -> pd.Series:\n",
    "    return p_values < alpha\n",
    "\n",
    "\n",
    "def get_summary_statistics(\n",
    "    dataset_conf: pd.DataFrame,\n",
    "    transformation: DistanceTransformation,\n",
    "    norm_method: Normalizer,\n",
    "    adjacency_method: AdjacencyMethod,\n",
    "    event_filename: str,\n",
    "    input_data: bool,\n",
    "    use_threshold: bool,\n",
    ") -> Dict[str, Any]:\n",
    "    df0 = dataset_conf[\n",
    "        (dataset_conf[\"transformation\"] == transformation.value)\n",
    "        & (dataset_conf[\"normalization\"] == norm_method.value)\n",
    "        & (dataset_conf[\"adjacency_method\"] == adjacency_method.value)\n",
    "    ].sort_values(by=\"intensity\")[[*METRIC_COLUMNS, \"intensity\"]]\n",
    "\n",
    "    x0 = df0.drop(columns=[\"intensity\"]).astype(float).values\n",
    "    y = (\n",
    "        df0[\"intensity\"]\n",
    "        .replace(\n",
    "            [\"G1\", \"G2\", \"G3\", \"G4\", \"G5\", \"Unknown\", np.nan, \"G4/G5\", \"G3/G4\"],\n",
    "            [1, 2, 3, 4, 5, 0, 0, 4.5, 3.5],\n",
    "        )\n",
    "        .astype(float)\n",
    "        .values\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        x0 = sm.add_constant(x0)  # Adds a constant term to the predictor\n",
    "        model = sm.OLS(y, x0).fit()\n",
    "        h0s = model.summary2().tables[1][\"P>|t|\"].drop(\"const\")\n",
    "        h0_count = h0s[h0_condition(h0s)].count()\n",
    "    except Exception as e:\n",
    "        dataset_name = encode_variables_to_filename(\n",
    "            event_filename=event_filename,\n",
    "            imput_data=input_data,\n",
    "            use_threshold=use_threshold,\n",
    "        )\n",
    "        print(f\"Error processing dataset: {dataset_name} -- {e}\")\n",
    "        print(\n",
    "            f\"transformation={transformation.value}, normalization={norm_method.value}, \"\n",
    "            f\"adjacency_method={adjacency_method.value}\"\n",
    "        )\n",
    "\n",
    "        raise e\n",
    "    \n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"count\": h0_count,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8096e431",
   "metadata": {},
   "source": [
    "### Bests configurations?\n",
    "\n",
    "Trying to do grid search, and take the bests combinations, what is the best combination? In this case, I'll take those combinations with the mosts amount of variables < 0.09, and save it in a .csv to read it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff9284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: dataset_all_imput-False_threshold-False.csv\n",
      "Processing dataset: dataset_all_imput-True_threshold-True.csv\n",
      "Processing dataset: dataset_all.original_imput-False_threshold-False.csv\n",
      "Processing dataset: dataset_all.original_imput-True_threshold-True.csv\n",
      "Processing dataset: dataset_all.imp_imput-False_threshold-False.csv\n",
      "Processing dataset: dataset_all.imp_imput-True_threshold-True.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_combinations = list(itertools.product(\n",
    "    [\"all.txt\", \"all.original.txt\", \"all.imp.txt\"],\n",
    "    [False, True],  # input_data == use_threshold\n",
    "))\n",
    "combinations_per_dataset = list(itertools.product(\n",
    "    DistanceTransformation,\n",
    "    Normalizer,\n",
    "    [AdjacencyMethod.MANHATTAN, AdjacencyMethod.MINKOWSKI],\n",
    "))\n",
    "\n",
    "dataset = {\n",
    "    \"event_filename\": [],\n",
    "    \"input_data\": [],\n",
    "    \"use_threshold\": [],\n",
    "    \"transformation\": [],\n",
    "    \"normalization\": [],\n",
    "    \"adjacency_method\": [],\n",
    "    \"count\": [],\n",
    "}\n",
    "for event_filename, input_data in dataset_combinations:\n",
    "    use_threshold = input_data\n",
    "    dataset_conf = get_dataset_filename(\n",
    "        event_filename=event_filename,\n",
    "        input_data=input_data,\n",
    "        use_threshold=use_threshold,\n",
    "    )\n",
    "    print(\n",
    "        \"Processing dataset: \"\n",
    "        f\"{encode_variables_to_filename(event_filename, input_data, use_threshold)}\"\n",
    "    )\n",
    "\n",
    "    for transformation, norm_method, adjacency_method in combinations_per_dataset:\n",
    "        results = get_summary_statistics(\n",
    "            dataset_conf=dataset_conf,\n",
    "            transformation=transformation,\n",
    "            norm_method=norm_method,\n",
    "            adjacency_method=adjacency_method,\n",
    "            event_filename=event_filename,\n",
    "            input_data=input_data,\n",
    "            use_threshold=use_threshold,\n",
    "        )\n",
    "        h0_count = results[\"count\"]\n",
    "\n",
    "        dataset[\"event_filename\"].append(event_filename)\n",
    "        dataset[\"input_data\"].append(input_data)\n",
    "        dataset[\"use_threshold\"].append(use_threshold)\n",
    "        dataset[\"transformation\"].append(transformation.value)\n",
    "        dataset[\"normalization\"].append(norm_method.value)\n",
    "        dataset[\"adjacency_method\"].append(adjacency_method.value)\n",
    "        dataset[\"count\"].append(int(h0_count))\n",
    "\n",
    "dataset_df = pd.DataFrame(dataset)\n",
    "dataset_df.to_csv(ROOTDIR / \"data\" / \"dataset_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd9f1a7",
   "metadata": {},
   "source": [
    "## Read best configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a61684a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_filename</th>\n",
       "      <th>input_data</th>\n",
       "      <th>use_threshold</th>\n",
       "      <th>transformation</th>\n",
       "      <th>normalization</th>\n",
       "      <th>adjacency_method</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>all.imp.txt</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>exponential</td>\n",
       "      <td>min_max</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>all.imp.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>exponential</td>\n",
       "      <td>min_max</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>all.original.txt</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>all.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>exponential</td>\n",
       "      <td>z_score</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>all.original.txt</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>exponential</td>\n",
       "      <td>robust</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>all.imp.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "      <td>decimal_scaling</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>all.imp.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>exponential</td>\n",
       "      <td>robust</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>all.imp.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>exponential</td>\n",
       "      <td>z_score</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>all.imp.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>exponential</td>\n",
       "      <td>decimal_scaling</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>all.imp.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>exponential</td>\n",
       "      <td>none</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       event_filename  input_data  use_threshold transformation  \\\n",
       "140       all.imp.txt       False          False    exponential   \n",
       "170       all.imp.txt        True           True    exponential   \n",
       "68   all.original.txt       False          False           none   \n",
       "52            all.txt        True           True    exponential   \n",
       "84   all.original.txt       False          False    exponential   \n",
       "..                ...         ...            ...            ...   \n",
       "167       all.imp.txt        True           True            log   \n",
       "175       all.imp.txt        True           True    exponential   \n",
       "172       all.imp.txt        True           True    exponential   \n",
       "177       all.imp.txt        True           True    exponential   \n",
       "179       all.imp.txt        True           True    exponential   \n",
       "\n",
       "       normalization adjacency_method  count  \n",
       "140          min_max        manhattan      4  \n",
       "170          min_max        manhattan      4  \n",
       "68              none        manhattan      4  \n",
       "52           z_score        manhattan      4  \n",
       "84            robust        manhattan      3  \n",
       "..               ...              ...    ...  \n",
       "167  decimal_scaling        minkowski      0  \n",
       "175           robust        minkowski      0  \n",
       "172          z_score        manhattan      0  \n",
       "177  decimal_scaling        minkowski      0  \n",
       "179             none        minkowski      0  \n",
       "\n",
       "[180 rows x 7 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = pd.read_csv(\n",
    "    ROOTDIR / \"data\" / \"dataset_summary.csv\", index_col=False\n",
    ").sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "027cb330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: dataset_all.imp_imput-False_threshold-False.csv\n",
      "Transformation: exponential, Normalization: min_max, Adjacency Method: manhattan\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.361\n",
      "Model:                            OLS   Adj. R-squared:                  0.041\n",
      "Method:                 Least Squares   F-statistic:                     1.129\n",
      "Date:                Mon, 09 Feb 2026   Prob (F-statistic):              0.386\n",
      "Time:                        19:05:10   Log-Likelihood:                -34.631\n",
      "No. Observations:                  34   AIC:                             93.26\n",
      "Df Residuals:                      22   BIC:                             111.6\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       -143.7612     72.530     -1.982      0.060    -294.178       6.656\n",
      "x1           113.3810     54.219      2.091      0.048       0.937     225.825\n",
      "x2            18.6722      8.748      2.134      0.044       0.529      36.815\n",
      "x3            -1.7600      1.371     -1.283      0.213      -4.604       1.084\n",
      "x4             0.2637      1.169      0.226      0.824      -2.160       2.688\n",
      "x5            -8.7973     10.077     -0.873      0.392     -29.696      12.101\n",
      "x6            -0.4826      1.649     -0.293      0.772      -3.902       2.937\n",
      "x7             0.1012      0.115      0.883      0.387      -0.136       0.339\n",
      "x8           514.9562    284.192      1.812      0.084     -74.422    1104.334\n",
      "x9           -53.2454     36.769     -1.448      0.162    -129.499      23.008\n",
      "x10            3.9719     27.073      0.147      0.885     -52.174      60.118\n",
      "x11         -383.4344    200.051     -1.917      0.068    -798.314      31.445\n",
      "==============================================================================\n",
      "Omnibus:                        2.242   Durbin-Watson:                   0.973\n",
      "Prob(Omnibus):                  0.326   Jarque-Bera (JB):                2.025\n",
      "Skew:                          -0.564   Prob(JB):                        0.363\n",
      "Kurtosis:                       2.604   Cond. No.                     1.43e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.43e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "\n",
      "\n",
      "Dataset name: dataset_all.imp_imput-True_threshold-True.csv\n",
      "Transformation: exponential, Normalization: min_max, Adjacency Method: manhattan\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.361\n",
      "Model:                            OLS   Adj. R-squared:                  0.041\n",
      "Method:                 Least Squares   F-statistic:                     1.129\n",
      "Date:                Mon, 09 Feb 2026   Prob (F-statistic):              0.386\n",
      "Time:                        19:05:18   Log-Likelihood:                -34.631\n",
      "No. Observations:                  34   AIC:                             93.26\n",
      "Df Residuals:                      22   BIC:                             111.6\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       -143.7612     72.530     -1.982      0.060    -294.178       6.656\n",
      "x1           113.3810     54.219      2.091      0.048       0.937     225.825\n",
      "x2            18.6722      8.748      2.134      0.044       0.529      36.815\n",
      "x3            -1.7600      1.371     -1.283      0.213      -4.604       1.084\n",
      "x4             0.2637      1.169      0.226      0.824      -2.160       2.688\n",
      "x5            -8.7973     10.077     -0.873      0.392     -29.696      12.101\n",
      "x6            -0.4826      1.649     -0.293      0.772      -3.902       2.937\n",
      "x7             0.1012      0.115      0.883      0.387      -0.136       0.339\n",
      "x8           514.9562    284.192      1.812      0.084     -74.422    1104.334\n",
      "x9           -53.2454     36.769     -1.448      0.162    -129.499      23.008\n",
      "x10            3.9719     27.073      0.147      0.885     -52.174      60.118\n",
      "x11         -383.4344    200.051     -1.917      0.068    -798.314      31.445\n",
      "==============================================================================\n",
      "Omnibus:                        2.242   Durbin-Watson:                   0.973\n",
      "Prob(Omnibus):                  0.326   Jarque-Bera (JB):                2.025\n",
      "Skew:                          -0.564   Prob(JB):                        0.363\n",
      "Kurtosis:                       2.604   Cond. No.                     1.43e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.43e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "\n",
      "\n",
      "Dataset name: dataset_all.original_imput-False_threshold-False.csv\n",
      "Transformation: none, Normalization: none, Adjacency Method: manhattan\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.508\n",
      "Model:                            OLS   Adj. R-squared:                  0.261\n",
      "Method:                 Least Squares   F-statistic:                     2.062\n",
      "Date:                Mon, 09 Feb 2026   Prob (F-statistic):             0.0716\n",
      "Time:                        19:05:24   Log-Likelihood:                -30.195\n",
      "No. Observations:                  34   AIC:                             84.39\n",
      "Df Residuals:                      22   BIC:                             102.7\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.4713     29.813     -0.016      0.988     -62.299      61.357\n",
      "x1         -2643.1199   1403.122     -1.884      0.073   -5553.017     266.777\n",
      "x2            -0.3135      1.057     -0.297      0.770      -2.506       1.879\n",
      "x3             3.2938      1.297      2.539      0.019       0.603       5.985\n",
      "x4            -0.9673      1.592     -0.608      0.550      -4.268       2.334\n",
      "x5             2.5283      2.619      0.965      0.345      -2.904       7.961\n",
      "x6           -19.1560      8.006     -2.393      0.026     -35.759      -2.553\n",
      "x7            -0.3860      0.257     -1.501      0.148      -0.919       0.147\n",
      "x8          3419.5884   1771.381      1.930      0.067    -254.031    7093.208\n",
      "x9           574.5792    449.717      1.278      0.215    -358.077    1507.235\n",
      "x10         -351.2254    281.245     -1.249      0.225    -934.492     232.041\n",
      "x11           87.5615    117.460      0.745      0.464    -156.036     331.159\n",
      "==============================================================================\n",
      "Omnibus:                        2.355   Durbin-Watson:                   1.184\n",
      "Prob(Omnibus):                  0.308   Jarque-Bera (JB):                1.368\n",
      "Skew:                          -0.465   Prob(JB):                        0.504\n",
      "Kurtosis:                       3.320   Cond. No.                     8.51e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 8.51e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "\n",
      "\n",
      "Dataset name: dataset_all_imput-True_threshold-True.csv\n",
      "Transformation: exponential, Normalization: z_score, Adjacency Method: manhattan\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.428\n",
      "Model:                            OLS   Adj. R-squared:                  0.142\n",
      "Method:                 Least Squares   F-statistic:                     1.497\n",
      "Date:                Mon, 09 Feb 2026   Prob (F-statistic):              0.202\n",
      "Time:                        19:05:31   Log-Likelihood:                -32.740\n",
      "No. Observations:                  34   AIC:                             89.48\n",
      "Df Residuals:                      22   BIC:                             107.8\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        115.4971     88.320      1.308      0.204     -67.666     298.661\n",
      "x1           -87.5446     69.148     -1.266      0.219    -230.949      55.860\n",
      "x2           -12.1844     12.101     -1.007      0.325     -37.280      12.911\n",
      "x3            -2.5502      1.071     -2.381      0.026      -4.771      -0.329\n",
      "x4            -0.1784      1.313     -0.136      0.893      -2.902       2.545\n",
      "x5            11.7148      8.888      1.318      0.201      -6.718      30.148\n",
      "x6             3.8581      1.457      2.648      0.015       0.836       6.880\n",
      "x7            -0.1081      0.087     -1.245      0.226      -0.288       0.072\n",
      "x8          -513.7791    283.499     -1.812      0.084   -1101.721      74.163\n",
      "x9            68.7800     41.815      1.645      0.114     -17.940     155.500\n",
      "x10           41.9448     28.162      1.489      0.151     -16.459     100.349\n",
      "x11          370.4774    177.380      2.089      0.049       2.613     738.342\n",
      "==============================================================================\n",
      "Omnibus:                        0.298   Durbin-Watson:                   0.741\n",
      "Prob(Omnibus):                  0.861   Jarque-Bera (JB):                0.091\n",
      "Skew:                           0.125   Prob(JB):                        0.956\n",
      "Kurtosis:                       2.956   Cond. No.                     1.47e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.47e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "\n",
      "\n",
      "Dataset name: dataset_all.original_imput-False_threshold-False.csv\n",
      "Transformation: exponential, Normalization: robust, Adjacency Method: manhattan\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.401\n",
      "Model:                            OLS   Adj. R-squared:                  0.101\n",
      "Method:                 Least Squares   F-statistic:                     1.336\n",
      "Date:                Mon, 09 Feb 2026   Prob (F-statistic):              0.270\n",
      "Time:                        19:05:37   Log-Likelihood:                -33.540\n",
      "No. Observations:                  34   AIC:                             91.08\n",
      "Df Residuals:                      22   BIC:                             109.4\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         14.9360     64.134      0.233      0.818    -118.070     147.942\n",
      "x1            67.1093     62.610      1.072      0.295     -62.736     196.955\n",
      "x2            -5.0049      9.141     -0.548      0.590     -23.962      13.953\n",
      "x3            -2.5362      1.110     -2.284      0.032      -4.839      -0.233\n",
      "x4            -1.3568      2.366     -0.573      0.572      -6.265       3.551\n",
      "x5            22.1911      9.135      2.429      0.024       3.246      41.136\n",
      "x6             3.5942      1.997      1.800      0.086      -0.547       7.736\n",
      "x7             0.0154      0.076      0.202      0.842      -0.143       0.173\n",
      "x8          -180.5399    251.348     -0.718      0.480    -701.804     340.724\n",
      "x9           -21.5095     49.806     -0.432      0.670    -124.801      81.782\n",
      "x10           22.4033     34.027      0.658      0.517     -48.164      92.971\n",
      "x11          103.0715    157.595      0.654      0.520    -223.762     429.904\n",
      "==============================================================================\n",
      "Omnibus:                        2.464   Durbin-Watson:                   0.473\n",
      "Prob(Omnibus):                  0.292   Jarque-Bera (JB):                1.525\n",
      "Skew:                           0.253   Prob(JB):                        0.466\n",
      "Kurtosis:                       2.094   Cond. No.                     1.13e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.13e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in dataset_df.head(5).itertuples():\n",
    "    event_filename = str(row.event_filename)\n",
    "    input_data = bool(row.input_data)\n",
    "    use_threshold = bool(row.use_threshold)\n",
    "    transformation = row.transformation\n",
    "    normalization = row.normalization\n",
    "    adjacency_method = row.adjacency_method\n",
    "\n",
    "    dataset_conf = get_dataset_filename(\n",
    "        event_filename=event_filename,\n",
    "        input_data=input_data,\n",
    "        use_threshold=use_threshold,\n",
    "    )\n",
    "\n",
    "    model = get_summary_statistics(\n",
    "        dataset_conf=dataset_conf,\n",
    "        transformation=DistanceTransformation(transformation),\n",
    "        norm_method=Normalizer(normalization),\n",
    "        adjacency_method=AdjacencyMethod(adjacency_method),\n",
    "        event_filename=event_filename,\n",
    "        input_data=input_data,\n",
    "        use_threshold=use_threshold,\n",
    "    )[\"model\"]\n",
    "\n",
    "    print(\n",
    "        \"Dataset name: \"\n",
    "        f\"{encode_variables_to_filename(event_filename, input_data, use_threshold)}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Transformation: {transformation}, Normalization: {normalization}, \"\n",
    "        f\"Adjacency Method: {adjacency_method}\"\n",
    "    )\n",
    "    print(model.summary())\n",
    "\n",
    "    print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
